"""
Test Suite for OpenFHE CKKS Attention Block Implementation

This test file validates the attention_openfhe.py implementation with:
- Basic functionality tests
- Different sequence lengths and dimensions
- Accuracy verification against NumPy reference
- Performance benchmarking
"""

import numpy as np
import time
import sys


def print_separator(char="=", length=80):
    """Print a separator line."""
    print(char * length)


def print_section(title):
    """Print a section header."""
    print(f"\n{title}")
    print_separator("-")


def compute_attention_metrics(predicted, reference):
    """Compute attention-specific metrics."""
    abs_error = np.abs(predicted - reference)

    metrics = {
        "max_error": np.max(abs_error),
        "mean_error": np.mean(abs_error),
        "relative_error": np.mean(abs_error / (np.abs(reference) + 1e-10)),
    }
    return metrics


def test_basic_functionality():
    """Test 1: Basic attention computation."""
    print_section("Test 1: Basic Attention Functionality")

    from attention_openfhe import AttentionBlockOpenFHE, numpy_attention, OPENFHE_AVAILABLE

    if not OPENFHE_AVAILABLE:
        print("‚ùå FAILED: OpenFHE not available")
        print("Install with: pip install openfhe openfhe_numpy")
        return False

    try:
        # Small test case
        seq_len, d_k, d_v = 4, 4, 4

        print(f"Configuration: seq_len={seq_len}, d_k={d_k}, d_v={d_v}")

        # Initialize attention block
        print("\nInitializing attention block...")
        start = time.time()
        attention = AttentionBlockOpenFHE(
            seq_len=seq_len,
            d_k=d_k,
            d_v=d_v,
            mult_depth=30,
            softmax_K=32,
            softmax_scale_factor=4
        )
        init_time = time.time() - start
        print(f"  Initialization: {init_time:.2f}s ‚úÖ")

        # Generate test inputs
        np.random.seed(42)
        Q = np.random.randn(seq_len, d_k) * 0.5  # Scale down for stability
        K = np.random.randn(seq_len, d_k) * 0.5
        V = np.random.randn(seq_len, d_v) * 0.5

        print(f"\nInput matrices:")
        print(f"  Q: {Q.shape}, range [{Q.min():.2f}, {Q.max():.2f}]")
        print(f"  K: {K.shape}, range [{K.min():.2f}, {K.max():.2f}]")
        print(f"  V: {V.shape}, range [{V.min():.2f}, {V.max():.2f}]")

        # Compute reference
        print("\nComputing reference (NumPy)...")
        ref_output, ref_weights = numpy_attention(Q, K, V)

        # Compute encrypted attention
        print("\nComputing encrypted attention...")
        start = time.time()
        enc_output, enc_weights = attention.attention_encrypted(Q, K, V)
        compute_time = time.time() - start

        print(f"\n{'='*80}")
        print("  Results")
        print("="*80)

        # Compare outputs
        output_metrics = compute_attention_metrics(enc_output, ref_output)
        weights_metrics = compute_attention_metrics(enc_weights, ref_weights)

        print(f"\nOutput comparison:")
        print(f"  Max error:      {output_metrics['max_error']:.6f}")
        print(f"  Mean error:     {output_metrics['mean_error']:.6f}")
        print(f"  Relative error: {output_metrics['relative_error']:.6f}")

        print(f"\nAttention weights comparison:")
        print(f"  Max error:      {weights_metrics['max_error']:.6f}")
        print(f"  Mean error:     {weights_metrics['mean_error']:.6f}")
        print(f"  Sum per row (ref):  {ref_weights.sum(axis=1)}")
        print(f"  Sum per row (enc):  {enc_weights.sum(axis=1)}")

        print(f"\nComputation time: {compute_time:.2f}s")

        # Pass criteria: softmax approximation introduces error
        passed = (output_metrics['max_error'] < 1.0 and
                 weights_metrics['max_error'] < 1.0)

        if passed:
            print("\n‚úÖ TEST 1 PASSED - Attention computation acceptable")
        else:
            print("\n‚ùå TEST 1 FAILED - Error too large")

        return passed, attention

    except Exception as e:
        print(f"\n‚ùå TEST 1 FAILED: {e}")
        import traceback
        traceback.print_exc()
        return False, None


def test_different_dimensions(attention):
    """Test 2: Different matrix dimensions."""
    print_section("Test 2: Different Dimensions")

    from attention_openfhe import numpy_attention

    # We can only test with the same dimensions as initialized
    # So we'll test different input values instead
    test_cases = [
        ("Random normal", lambda s, d1, d2: np.random.randn(s, d1) * 0.5),
        ("Small values", lambda s, d1, d2: np.random.randn(s, d1) * 0.1),
        ("Identity-like", lambda s, d1, d2: np.eye(s, d1)),
    ]

    all_passed = True
    seq_len, d_k, d_v = attention.seq_len, attention.d_k, attention.d_v

    for name, generator in test_cases:
        try:
            print(f"\n  Testing: {name}")
            Q = generator(seq_len, d_k, d_k)
            K = generator(seq_len, d_k, d_k)
            V = generator(seq_len, d_v, d_v)

            # Reference
            ref_output, _ = numpy_attention(Q, K, V)

            # Encrypted
            enc_output, _ = attention.attention_encrypted(Q, K, V)

            # Metrics
            metrics = compute_attention_metrics(enc_output, ref_output)

            passed = metrics['max_error'] < 1.0
            status = "‚úÖ" if passed else "‚ùå"

            print(f"    Max error: {metrics['max_error']:.4f} {status}")

            if not passed:
                all_passed = False

        except Exception as e:
            print(f"    ‚ùå Exception: {e}")
            all_passed = False

    if all_passed:
        print("\n‚úÖ TEST 2 PASSED - All dimensions handled")
    else:
        print("\n‚ùå TEST 2 FAILED - Some dimensions failed")

    return all_passed


def test_attention_properties():
    """Test 3: Verify attention properties."""
    print_section("Test 3: Attention Properties")

    from attention_openfhe import AttentionBlockOpenFHE, numpy_attention

    try:
        # Initialize small attention for testing
        seq_len, d_k, d_v = 4, 4, 4

        print("Initializing attention block...")
        attention = AttentionBlockOpenFHE(
            seq_len=seq_len,
            d_k=d_k,
            d_v=d_v,
            mult_depth=30,
            softmax_K=32,
            softmax_scale_factor=4
        )

        np.random.seed(123)
        Q = np.random.randn(seq_len, d_k) * 0.5
        K = np.random.randn(seq_len, d_k) * 0.5
        V = np.random.randn(seq_len, d_v) * 0.5

        print("\nComputing attention...")
        enc_output, enc_weights = attention.attention_encrypted(Q, K, V)

        # Property 1: Attention weights sum to ~1 per row
        print("\nProperty 1: Attention weights sum to ~1.0 per row")
        weight_sums = enc_weights.sum(axis=1)
        print(f"  Weight sums per row: {weight_sums}")
        print(f"  Mean sum: {weight_sums.mean():.4f}")
        print(f"  Std sum:  {weight_sums.std():.4f}")

        sum_close_to_one = np.allclose(weight_sums, 1.0, atol=0.5)
        print(f"  Close to 1.0? {sum_close_to_one} {'‚úÖ' if sum_close_to_one else '‚ö†Ô∏è'}")

        # Property 2: Output is linear combination of V
        print("\nProperty 2: Output is weighted combination of V")
        # Check if output magnitude is reasonable
        v_magnitude = np.linalg.norm(V)
        output_magnitude = np.linalg.norm(enc_output)
        ratio = output_magnitude / v_magnitude
        print(f"  ||V||:      {v_magnitude:.4f}")
        print(f"  ||Output||: {output_magnitude:.4f}")
        print(f"  Ratio:      {ratio:.4f}")

        magnitude_reasonable = 0.1 < ratio < 10.0
        print(f"  Reasonable? {magnitude_reasonable} {'‚úÖ' if magnitude_reasonable else '‚ö†Ô∏è'}")

        passed = sum_close_to_one and magnitude_reasonable

        if passed:
            print("\n‚úÖ TEST 3 PASSED - Attention properties verified")
        else:
            print("\n‚ö†Ô∏è  TEST 3 WARNING - Some properties violated (may be due to approximation)")

        return passed

    except Exception as e:
        print(f"\n‚ùå TEST 3 FAILED: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_performance_benchmark():
    """Test 4: Performance benchmark."""
    print_section("Test 4: Performance Benchmark")

    from attention_openfhe import AttentionBlockOpenFHE, numpy_attention

    configs = [
        ("Small (4x4x4)", 4, 4, 4),
        ("Medium (8x8x8)", 8, 8, 8),
    ]

    print("\nBenchmarking different configurations...\n")
    print(f"{'Configuration':<20} {'Init (s)':<12} {'Compute (s)':<12} {'Max Error':<12}")
    print_separator("-")

    all_passed = True

    for name, seq_len, d_k, d_v in configs:
        try:
            # Initialize
            start = time.time()
            attention = AttentionBlockOpenFHE(
                seq_len=seq_len,
                d_k=d_k,
                d_v=d_v,
                mult_depth=30,
                softmax_K=32,
                softmax_scale_factor=4
            )
            init_time = time.time() - start

            # Generate inputs
            np.random.seed(42)
            Q = np.random.randn(seq_len, d_k) * 0.5
            K = np.random.randn(seq_len, d_k) * 0.5
            V = np.random.randn(seq_len, d_v) * 0.5

            # Reference
            ref_output, _ = numpy_attention(Q, K, V)

            # Compute
            start = time.time()
            enc_output, _ = attention.attention_encrypted(Q, K, V)
            compute_time = time.time() - start

            # Metrics
            max_error = np.max(np.abs(enc_output - ref_output))

            print(f"{name:<20} {init_time:<12.2f} {compute_time:<12.2f} {max_error:<12.4f}")

        except Exception as e:
            print(f"{name:<20} FAILED: {e}")
            all_passed = False

    if all_passed:
        print("\n‚úÖ TEST 4 PASSED - Performance benchmarked")
    else:
        print("\n‚ùå TEST 4 FAILED - Some configs failed")

    return all_passed


def main():
    """Run all tests."""
    print_separator("=")
    print("  OPENFHE CKKS ATTENTION BLOCK - TEST SUITE")
    print_separator("=")

    print("\nNote: Attention uses polynomial softmax approximation in CKKS.")
    print("Expect some approximation error (~0.1-1.0).")

    # Run tests
    test_results = {}

    # Test 1: Basic functionality
    result = test_basic_functionality()
    if isinstance(result, tuple):
        passed, attention = result
        test_results["Basic Functionality"] = passed
    else:
        test_results["Basic Functionality"] = False
        attention = None

    if not test_results["Basic Functionality"]:
        print("\n‚ö†Ô∏è  Stopping tests - basic functionality failed")
        sys.exit(1)

    # Test 2: Different dimensions
    test_results["Different Dimensions"] = test_different_dimensions(attention)

    # Test 3: Attention properties
    test_results["Attention Properties"] = test_attention_properties()

    # Test 4: Performance
    test_results["Performance Benchmark"] = test_performance_benchmark()

    # Summary
    print_separator("=")
    print("  TEST SUMMARY")
    print_separator("=")

    for test_name, passed in test_results.items():
        status = "‚úÖ PASSED" if passed else "‚ùå FAILED"
        print(f"  {test_name:<30} {status}")

    print_separator("=")

    passed_count = sum(test_results.values())
    total_count = len(test_results)
    print(f"\n  Results: {passed_count}/{total_count} tests passed")

    if passed_count == total_count:
        print("\n  üéâ ALL TESTS PASSED! üéâ")
        print("\n  Note: Attention approximation has inherent error due to:")
        print("  - Polynomial softmax approximation (~0.2 error)")
        print("  - CKKS noise accumulation")
        print("  - Matrix packing/unpacking overhead")
    else:
        print(f"\n  ‚ö†Ô∏è  {total_count - passed_count} test(s) failed")

    print_separator("=")

    return passed_count == total_count


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
